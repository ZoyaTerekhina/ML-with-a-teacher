Проект "Отток клиентов"

Задача проекта:

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.

Источник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

Признаки

RowNumber — индекс строки в данных
CustomerId — уникальный идентификатор клиента
Surname — фамилия
CreditScore — кредитный рейтинг
Geography — страна проживания
Gender — пол
Age — возраст
Tenure — сколько лет человек является клиентом банка
Balance — баланс на счёте
NumOfProducts — количество продуктов банка, используемых клиентом
HasCrCard — наличие кредитной карты
IsActiveMember — активность клиента
EstimatedSalary — предполагаемая зарплата

Целевой признак

Exited — факт ухода клиента

В ходе нашей работы мы подготовили данные датасета и провели исследование, в ходе которого выявили дисбаланс классов. Класс "0" примерно в 4 раза больше класса "1".

Далее рассмотрели три модели (Решающее дерево, Случайный лес и Логистическую регрессию) и обучили их без учета дисбаланса. Полученные метрики F1 были меньше необходимого по ТЗ проекта значения (0.59)

На следующем этапе работы мы попытались улучшить качество моделей, учитывая дисбаланс классов. Для борьбы с дисбалансом использовалось несколько методов:

    Взвешивание классов
    Увеличение числа обектов обучающей выборки меньшего класса с помощью функции upsampling
    Уменьшение числа объектов обучающей выборки большего класса с помощью функции downsampling

В результате борьбы с дисбалансом лучшей оказалась модель Случайного леса. Причем показала она хорошие результаты на валидационной выборке и при взвешивании классов и при обучении на увеличенной обучающей выборке - увеличенном количестве объектов меньшего класса с помощью функции upsampling. Значение метрики F1 (0.6031) незначительно, но выше при обучении Случайного леса на увеличенной обучающей выборке, поэтому именно на этой модели (с параметрами максимальной глубины 19 и количеством деревьев 40 (max_depth=19, n_estimators=40)) мы остановились и протестировали ее на тестовой выборке.

На тестовой выборке наша модель дала F1=0.6079 (было до правок 0.5916), что больше 0.59 и соотвествует ТЗ данного проекта.

Проверка модели на адекватность показала,что результат работы обученной модели лучше случайных результатов.  